{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Yewp0TEGl_kt",
        "outputId": "ff6e1508-2f94-4fb2-9b5c-4be14d8bf583"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
            "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.2.5\n",
            "    Uninstalling numpy-2.2.5:\n",
            "      Successfully uninstalled numpy-2.2.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --force-reinstall numpy pandas --upgrade\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "YUsPMeSFofef",
        "outputId": "dda5ade4-1987-4cbf-bfaa-4544aee202b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy\n",
            "  Using cached numpy-2.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Collecting pandas\n",
            "  Using cached pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
            "Collecting python-dateutil>=2.8.2 (from pandas)\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting pytz>=2020.1 (from pandas)\n",
            "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas)\n",
            "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting six>=1.5 (from python-dateutil>=2.8.2->pandas)\n",
            "  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Using cached numpy-2.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "Using cached pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.2/509.2 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.8/347.8 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Installing collected packages: pytz, tzdata, six, numpy, python-dateutil, pandas\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2025.2\n",
            "    Uninstalling pytz-2025.2:\n",
            "      Successfully uninstalled pytz-2025.2\n",
            "  Attempting uninstall: tzdata\n",
            "    Found existing installation: tzdata 2025.2\n",
            "    Uninstalling tzdata-2025.2:\n",
            "      Successfully uninstalled tzdata-2025.2\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.17.0\n",
            "    Uninstalling six-1.17.0:\n",
            "      Successfully uninstalled six-1.17.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: python-dateutil\n",
            "    Found existing installation: python-dateutil 2.9.0.post0\n",
            "    Uninstalling python-dateutil-2.9.0.post0:\n",
            "      Successfully uninstalled python-dateutil-2.9.0.post0\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.3\n",
            "    Uninstalling pandas-2.2.3:\n",
            "      Successfully uninstalled pandas-2.2.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.2.5 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.5 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.2.5 pandas-2.2.3 python-dateutil-2.9.0.post0 pytz-2025.2 six-1.17.0 tzdata-2025.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "dateutil",
                  "pytz",
                  "six"
                ]
              },
              "id": "7e8d6b38160a4dcebddd85656dec91e6"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#First"
      ],
      "metadata": {
        "id": "LbWMTI5Lmhtl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "8YuhkrwEmdgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download NLTK stopwords (only once)\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUr0bdOdmd-t",
        "outputId": "01fbfabc-0eab-43b8-f1e3-25f8f098621b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Sentences and Labels\n",
        "positive_sentences = [\n",
        "    \"The unclean room was finally cleaned!!! and looked beautiful.\",\n",
        "    \"Even the unclean utensils were washed and organized nicely.\",\n",
        "    \"He saw the unclean water but fixed the source quickly.\",\n",
        "    \"The unclean city streets were transformed into green parks.\",\n",
        "    \"Though it was unclean, the area was sanitized with care.\"\n",
        "]\n",
        "\n",
        "negative_sentences = [\n",
        "    \"The unclean23 bathroom smelled terrible and was unusable.\",\n",
        "    \"Unclean food caused food poisoning at the party.\",\n",
        "    \"She disliked the unclean environment of the hostel.\",\n",
        "    \"The unclean river emitted a foul odor.@\",\n",
        "    \"They were disgusted by the unclean conditions in the hotel.\"\n",
        "]\n",
        "\n",
        "sentences = positive_sentences + negative_sentences\n",
        "labels = [1]*5 + [0]*5  # 1 = Positive, 0 = Negative"
      ],
      "metadata": {
        "id": "P6JbDz8emebl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Preprocessing with stop word removal\n",
        "def preprocess(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove punctuation/numbers\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # Normalize spaces\n",
        "    words = text.split()\n",
        "    filtered_words = [word for word in words if word not in stop_words]\n",
        "    return ' '.join(filtered_words)\n",
        "\n",
        "cleaned_sentences = [preprocess(s) for s in sentences]\n",
        "print(\"\\n--- Cleaned Sentences (Stopwords Removed) ---\")\n",
        "for i, s in enumerate(cleaned_sentences):\n",
        "    print(f\"{i+1}. {s}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyBDWUlymezx",
        "outputId": "b32c7027-fb2b-4bfb-b6c9-b5627cdf33b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Cleaned Sentences (Stopwords Removed) ---\n",
            "1. unclean room finally cleaned looked beautiful\n",
            "2. even unclean utensils washed organized nicely\n",
            "3. saw unclean water fixed source quickly\n",
            "4. unclean city streets transformed green parks\n",
            "5. though unclean area sanitized care\n",
            "6. unclean bathroom smelled terrible unusable\n",
            "7. unclean food caused food poisoning party\n",
            "8. disliked unclean environment hostel\n",
            "9. unclean river emitted foul odor\n",
            "10. disgusted unclean conditions hotel\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. One Hot Encoding (binary=True)\n",
        "vectorizer_onehot = CountVectorizer(binary=True)\n",
        "X_onehot = vectorizer_onehot.fit_transform(cleaned_sentences).toarray()\n",
        "print(\"\\n--- One Hot Encoding ---\")\n",
        "print(pd.DataFrame(X_onehot, columns=vectorizer_onehot.get_feature_names_out()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9zur-yMpQ_z",
        "outputId": "ea34a62a-31d8-479c-dd98-24783de35907"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- One Hot Encoding ---\n",
            "   area  bathroom  beautiful  care  caused  city  cleaned  conditions  \\\n",
            "0     0         0          1     0       0     0        1           0   \n",
            "1     0         0          0     0       0     0        0           0   \n",
            "2     0         0          0     0       0     0        0           0   \n",
            "3     0         0          0     0       0     1        0           0   \n",
            "4     1         0          0     1       0     0        0           0   \n",
            "5     0         1          0     0       0     0        0           0   \n",
            "6     0         0          0     0       1     0        0           0   \n",
            "7     0         0          0     0       0     0        0           0   \n",
            "8     0         0          0     0       0     0        0           0   \n",
            "9     0         0          0     0       0     0        0           1   \n",
            "\n",
            "   disgusted  disliked  ...  source  streets  terrible  though  transformed  \\\n",
            "0          0         0  ...       0        0         0       0            0   \n",
            "1          0         0  ...       0        0         0       0            0   \n",
            "2          0         0  ...       1        0         0       0            0   \n",
            "3          0         0  ...       0        1         0       0            1   \n",
            "4          0         0  ...       0        0         0       1            0   \n",
            "5          0         0  ...       0        0         1       0            0   \n",
            "6          0         0  ...       0        0         0       0            0   \n",
            "7          0         1  ...       0        0         0       0            0   \n",
            "8          0         0  ...       0        0         0       0            0   \n",
            "9          1         0  ...       0        0         0       0            0   \n",
            "\n",
            "   unclean  unusable  utensils  washed  water  \n",
            "0        1         0         0       0      0  \n",
            "1        1         0         1       1      0  \n",
            "2        1         0         0       0      1  \n",
            "3        1         0         0       0      0  \n",
            "4        1         0         0       0      0  \n",
            "5        1         1         0       0      0  \n",
            "6        1         0         0       0      0  \n",
            "7        1         0         0       0      0  \n",
            "8        1         0         0       0      0  \n",
            "9        1         0         0       0      0  \n",
            "\n",
            "[10 rows x 43 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. TF-IDF\n",
        "vectorizer_tfidf = TfidfVectorizer()\n",
        "X_tfidf = vectorizer_tfidf.fit_transform(cleaned_sentences).toarray()\n",
        "print(\"\\n--- TF-IDF Encoding ---\")\n",
        "print(pd.DataFrame(X_tfidf, columns=vectorizer_tfidf.get_feature_names_out()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8ueXUUtpRPW",
        "outputId": "ba641fd9-e664-48fa-8e0d-b1a69e664397"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- TF-IDF Encoding ---\n",
            "      area  bathroom  beautiful     care    caused      city   cleaned  \\\n",
            "0  0.00000   0.00000   0.441223  0.00000  0.000000  0.000000  0.441223   \n",
            "1  0.00000   0.00000   0.000000  0.00000  0.000000  0.000000  0.000000   \n",
            "2  0.00000   0.00000   0.000000  0.00000  0.000000  0.000000  0.000000   \n",
            "3  0.00000   0.00000   0.000000  0.00000  0.000000  0.441223  0.000000   \n",
            "4  0.49167   0.00000   0.000000  0.49167  0.000000  0.000000  0.000000   \n",
            "5  0.00000   0.49167   0.000000  0.00000  0.000000  0.000000  0.000000   \n",
            "6  0.00000   0.00000   0.000000  0.00000  0.374327  0.000000  0.000000   \n",
            "7  0.00000   0.00000   0.000000  0.00000  0.000000  0.000000  0.000000   \n",
            "8  0.00000   0.00000   0.000000  0.00000  0.000000  0.000000  0.000000   \n",
            "9  0.00000   0.00000   0.000000  0.00000  0.000000  0.000000  0.000000   \n",
            "\n",
            "   conditions  disgusted  disliked  ...    source   streets  terrible  \\\n",
            "0     0.00000    0.00000   0.00000  ...  0.000000  0.000000   0.00000   \n",
            "1     0.00000    0.00000   0.00000  ...  0.000000  0.000000   0.00000   \n",
            "2     0.00000    0.00000   0.00000  ...  0.441223  0.000000   0.00000   \n",
            "3     0.00000    0.00000   0.00000  ...  0.000000  0.441223   0.00000   \n",
            "4     0.00000    0.00000   0.00000  ...  0.000000  0.000000   0.00000   \n",
            "5     0.00000    0.00000   0.00000  ...  0.000000  0.000000   0.49167   \n",
            "6     0.00000    0.00000   0.00000  ...  0.000000  0.000000   0.00000   \n",
            "7     0.00000    0.00000   0.56463  ...  0.000000  0.000000   0.00000   \n",
            "8     0.00000    0.00000   0.00000  ...  0.000000  0.000000   0.00000   \n",
            "9     0.56463    0.56463   0.00000  ...  0.000000  0.000000   0.00000   \n",
            "\n",
            "    though  transformed   unclean  unusable  utensils    washed     water  \n",
            "0  0.00000     0.000000  0.163129   0.00000  0.000000  0.000000  0.000000  \n",
            "1  0.00000     0.000000  0.163129   0.00000  0.441223  0.441223  0.000000  \n",
            "2  0.00000     0.000000  0.163129   0.00000  0.000000  0.000000  0.441223  \n",
            "3  0.00000     0.441223  0.163129   0.00000  0.000000  0.000000  0.000000  \n",
            "4  0.49167     0.000000  0.181780   0.00000  0.000000  0.000000  0.000000  \n",
            "5  0.00000     0.000000  0.181780   0.49167  0.000000  0.000000  0.000000  \n",
            "6  0.00000     0.000000  0.138396   0.00000  0.000000  0.000000  0.000000  \n",
            "7  0.00000     0.000000  0.208755   0.00000  0.000000  0.000000  0.000000  \n",
            "8  0.00000     0.000000  0.181780   0.00000  0.000000  0.000000  0.000000  \n",
            "9  0.00000     0.000000  0.208755   0.00000  0.000000  0.000000  0.000000  \n",
            "\n",
            "[10 rows x 43 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Bag of Words (BoW) - frequency-based\n",
        "vectorizer_bow = CountVectorizer(binary=False)\n",
        "X_bow = vectorizer_bow.fit_transform(cleaned_sentences).toarray()\n",
        "print(\"\\n--- Bag of Words (BoW) ---\")\n",
        "print(pd.DataFrame(X_bow, columns=vectorizer_bow.get_feature_names_out()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfI7bKU_pSNO",
        "outputId": "b551b636-bd82-4747-b462-f90a0b9b633b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Bag of Words (BoW) ---\n",
            "   area  bathroom  beautiful  care  caused  city  cleaned  conditions  \\\n",
            "0     0         0          1     0       0     0        1           0   \n",
            "1     0         0          0     0       0     0        0           0   \n",
            "2     0         0          0     0       0     0        0           0   \n",
            "3     0         0          0     0       0     1        0           0   \n",
            "4     1         0          0     1       0     0        0           0   \n",
            "5     0         1          0     0       0     0        0           0   \n",
            "6     0         0          0     0       1     0        0           0   \n",
            "7     0         0          0     0       0     0        0           0   \n",
            "8     0         0          0     0       0     0        0           0   \n",
            "9     0         0          0     0       0     0        0           1   \n",
            "\n",
            "   disgusted  disliked  ...  source  streets  terrible  though  transformed  \\\n",
            "0          0         0  ...       0        0         0       0            0   \n",
            "1          0         0  ...       0        0         0       0            0   \n",
            "2          0         0  ...       1        0         0       0            0   \n",
            "3          0         0  ...       0        1         0       0            1   \n",
            "4          0         0  ...       0        0         0       1            0   \n",
            "5          0         0  ...       0        0         1       0            0   \n",
            "6          0         0  ...       0        0         0       0            0   \n",
            "7          0         1  ...       0        0         0       0            0   \n",
            "8          0         0  ...       0        0         0       0            0   \n",
            "9          1         0  ...       0        0         0       0            0   \n",
            "\n",
            "   unclean  unusable  utensils  washed  water  \n",
            "0        1         0         0       0      0  \n",
            "1        1         0         1       1      0  \n",
            "2        1         0         0       0      1  \n",
            "3        1         0         0       0      0  \n",
            "4        1         0         0       0      0  \n",
            "5        1         1         0       0      0  \n",
            "6        1         0         0       0      0  \n",
            "7        1         0         0       0      0  \n",
            "8        1         0         0       0      0  \n",
            "9        1         0         0       0      0  \n",
            "\n",
            "[10 rows x 43 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Train/Test Split\n",
        "y = np.array(labels)\n",
        "X_train_oh, X_test_oh, y_train, y_test = train_test_split(X_onehot, y, test_size=0.3, random_state=42)\n",
        "X_train_tfidf, X_test_tfidf = train_test_split(X_tfidf, test_size=0.3, random_state=42)\n",
        "X_train_bow, X_test_bow = train_test_split(X_bow, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "sUTDfjvZpSGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. SVM Training and Evaluation\n",
        "def train_evaluate(X_train, X_test, y_train, y_test, name):\n",
        "    model = SVC(kernel='linear')\n",
        "    model.fit(X_train, y_train)\n",
        "    preds = model.predict(X_test)\n",
        "    acc = accuracy_score(y_test, preds)\n",
        "    print(f\"\\n✅ {name} Accuracy: {acc:.2f}\")\n",
        "\n",
        "train_evaluate(X_train_oh, X_test_oh, y_train, y_test, \"One Hot Encoding\")\n",
        "train_evaluate(X_train_tfidf, X_test_tfidf, y_train, y_test, \"TF-IDF\")\n",
        "train_evaluate(X_train_bow, X_test_bow, y_train, y_test, \"BoW (Frequency)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhJ45phJpRmg",
        "outputId": "e7699862-280b-479e-bf74-4b4c2cc86500"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ One Hot Encoding Accuracy: 0.67\n",
            "\n",
            "✅ TF-IDF Accuracy: 0.33\n",
            "\n",
            "✅ BoW (Frequency) Accuracy: 0.33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Second"
      ],
      "metadata": {
        "id": "imA0n1-bp7kv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade numpy\n",
        "!pip install --force-reinstall --no-cache-dir gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 946
        },
        "id": "yKRrY3yEqEm0",
        "outputId": "44a3f651-d02b-4c1e-edc4-0422f34a9c6e",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.2.5)\n",
            "Collecting gensim\n",
            "  Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
            "  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting smart-open>=1.8.1 (from gensim)\n",
            "  Downloading smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting wrapt (from smart-open>=1.8.1->gensim)\n",
            "  Downloading wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
            "Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m182.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m145.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m175.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 kB\u001b[0m \u001b[31m145.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (83 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.2/83.2 kB\u001b[0m \u001b[31m182.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: wrapt, numpy, smart-open, scipy, gensim\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.17.2\n",
            "    Uninstalling wrapt-1.17.2:\n",
            "      Successfully uninstalled wrapt-1.17.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.2.5\n",
            "    Uninstalling numpy-2.2.5:\n",
            "      Successfully uninstalled numpy-2.2.5\n",
            "  Attempting uninstall: smart-open\n",
            "    Found existing installation: smart-open 7.1.0\n",
            "    Uninstalling smart-open-7.1.0:\n",
            "      Successfully uninstalled smart-open-7.1.0\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.13.1\n",
            "    Uninstalling scipy-1.13.1:\n",
            "      Successfully uninstalled scipy-1.13.1\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 4.3.3\n",
            "    Uninstalling gensim-4.3.3:\n",
            "      Successfully uninstalled gensim-4.3.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gensim-4.3.3 numpy-1.26.4 scipy-1.13.1 smart-open-7.1.0 wrapt-1.17.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "smart_open",
                  "wrapt"
                ]
              },
              "id": "87c5fc8afda2470596ffb25088a5f6e7"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "nqEasB50p5Yi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Sentences and Labels\n",
        "positive_sentences = [\n",
        "    \"The unclean room was finally cleaned and looked beautiful.\",\n",
        "    \"Even the unclean utensils were washed and organized nicely.\",\n",
        "    \"He saw the unclean water but fixed the source quickly.\",\n",
        "    \"The unclean city streets were transformed into green parks.\",\n",
        "    \"Though it was unclean, the area was sanitized with care.\"\n",
        "]\n",
        "\n",
        "negative_sentences = [\n",
        "    \"The unclean bathroom smelled terrible and was unusable.\",\n",
        "    \"Unclean food caused food poisoning at the party.\",\n",
        "    \"She disliked the unclean environment of the hostel.\",\n",
        "    \"The unclean river emitted a foul odor.\",\n",
        "    \"They were disgusted by the unclean conditions in the hotel.\"\n",
        "]\n",
        "\n",
        "sentences = positive_sentences + negative_sentences\n",
        "labels = [1]*5 + [0]*5  # 1 = Positive, 0 = Negative\n"
      ],
      "metadata": {
        "id": "0KP9TnZYp5w7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Preprocessing and Tokenization\n",
        "def preprocess(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "cleaned_sentences = [preprocess(s) for s in sentences]\n",
        "tokenized_sentences = [s.split() for s in cleaned_sentences]\n",
        "print(\"\\n--- Tokenized Sentences ---\")\n",
        "for i, tokens in enumerate(tokenized_sentences):\n",
        "    print(f\"{i+1}. {tokens}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ge1gYoqtp6C8",
        "outputId": "1135c48d-303a-4ba5-cbac-3b3754c103ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Tokenized Sentences ---\n",
            "1. ['the', 'unclean', 'room', 'was', 'finally', 'cleaned', 'and', 'looked', 'beautiful']\n",
            "2. ['even', 'the', 'unclean', 'utensils', 'were', 'washed', 'and', 'organized', 'nicely']\n",
            "3. ['he', 'saw', 'the', 'unclean', 'water', 'but', 'fixed', 'the', 'source', 'quickly']\n",
            "4. ['the', 'unclean', 'city', 'streets', 'were', 'transformed', 'into', 'green', 'parks']\n",
            "5. ['though', 'it', 'was', 'unclean', 'the', 'area', 'was', 'sanitized', 'with', 'care']\n",
            "6. ['the', 'unclean', 'bathroom', 'smelled', 'terrible', 'and', 'was', 'unusable']\n",
            "7. ['unclean', 'food', 'caused', 'food', 'poisoning', 'at', 'the', 'party']\n",
            "8. ['she', 'disliked', 'the', 'unclean', 'environment', 'of', 'the', 'hostel']\n",
            "9. ['the', 'unclean', 'river', 'emitted', 'a', 'foul', 'odor']\n",
            "10. ['they', 'were', 'disgusted', 'by', 'the', 'unclean', 'conditions', 'in', 'the', 'hotel']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Train Word2Vec Model (CBOW = sg=0)\n",
        "w2v_model = Word2Vec(sentences=tokenized_sentences, vector_size=50, window=3, min_count=1, sg=0, epochs=300)"
      ],
      "metadata": {
        "id": "RSl-OAdLp6W8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Get Sentence Vectors (average of word vectors)\n",
        "def get_sentence_vector(tokens):\n",
        "    vectors = [w2v_model.wv[word] for word in tokens if word in w2v_model.wv]\n",
        "    return np.mean(vectors, axis=0) if vectors else np.zeros(50)\n",
        "\n",
        "X_w2v = np.array([get_sentence_vector(tokens) for tokens in tokenized_sentences])\n",
        "print(\"\\n--- Word2Vec Sentence Embeddings ---\")\n",
        "print(pd.DataFrame(X_w2v).round(3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCeKrWsHp6ts",
        "outputId": "06660d1c-09cd-4317-83d2-990187e3eb76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Word2Vec Sentence Embeddings ---\n",
            "      0      1      2      3      4      5      6      7      8      9   ...  \\\n",
            "0  0.002  0.009 -0.040  0.177  0.014  0.001  0.252  0.196 -0.273 -0.013  ...   \n",
            "1  0.007  0.008 -0.036  0.169  0.008  0.001  0.233  0.186 -0.262 -0.015  ...   \n",
            "2 -0.003  0.014 -0.042  0.189  0.010 -0.002  0.262  0.203 -0.290 -0.019  ...   \n",
            "3  0.001  0.006 -0.032  0.173 -0.002  0.001  0.245  0.185 -0.279 -0.018  ...   \n",
            "4 -0.004  0.003 -0.042  0.195  0.021 -0.003  0.261  0.204 -0.298 -0.011  ...   \n",
            "5 -0.001  0.008 -0.044  0.187  0.016  0.003  0.253  0.189 -0.284 -0.012  ...   \n",
            "6  0.007  0.014 -0.035  0.158 -0.002 -0.000  0.231  0.180 -0.250 -0.015  ...   \n",
            "7  0.006  0.011 -0.035  0.183 -0.000 -0.002  0.234  0.182 -0.269 -0.019  ...   \n",
            "8  0.001  0.006 -0.041  0.168  0.006  0.014  0.232  0.172 -0.245 -0.017  ...   \n",
            "9  0.002  0.011 -0.034  0.189  0.013 -0.000  0.257  0.198 -0.289 -0.012  ...   \n",
            "\n",
            "      40     41     42     43     44     45     46     47     48     49  \n",
            "0  0.149 -0.067 -0.061  0.013  0.127 -0.164 -0.067 -0.147  0.118  0.271  \n",
            "1  0.132 -0.064 -0.064  0.022  0.124 -0.153 -0.065 -0.137  0.108  0.244  \n",
            "2  0.148 -0.070 -0.067  0.011  0.144 -0.169 -0.076 -0.149  0.123  0.268  \n",
            "3  0.147 -0.066 -0.070  0.021  0.135 -0.158 -0.073 -0.142  0.117  0.253  \n",
            "4  0.144 -0.071 -0.072  0.013  0.142 -0.166 -0.087 -0.153  0.132  0.281  \n",
            "5  0.144 -0.073 -0.069  0.007  0.125 -0.164 -0.074 -0.143  0.120  0.267  \n",
            "6  0.125 -0.066 -0.049  0.006  0.126 -0.149 -0.056 -0.135  0.119  0.228  \n",
            "7  0.141 -0.065 -0.066  0.009  0.121 -0.164 -0.077 -0.134  0.110  0.254  \n",
            "8  0.131 -0.058 -0.062  0.030  0.120 -0.154 -0.074 -0.135  0.112  0.244  \n",
            "9  0.150 -0.070 -0.063  0.022  0.134 -0.156 -0.083 -0.148  0.126  0.264  \n",
            "\n",
            "[10 rows x 50 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Train/Test Split\n",
        "y = np.array(labels)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_w2v, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "KnRvPV2wp7D1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Train SVM\n",
        "model = SVC(kernel='linear')\n",
        "model.fit(X_train, y_train)\n",
        "preds = model.predict(X_test)"
      ],
      "metadata": {
        "id": "O0MLaodAqqrv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Evaluate\n",
        "acc = accuracy_score(y_test, preds)\n",
        "print(f\"\\n✅ Word2Vec Accuracy: {acc:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSFhKDAAqq-P",
        "outputId": "25cdb362-31ac-45fa-d553-12f96c4776fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Word2Vec Accuracy: 0.33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Third"
      ],
      "metadata": {
        "id": "wXDysUlA02gU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import re\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "-GhC_uLk0wC2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Sentences and Labels\n",
        "positive_sentences = [\n",
        "    \"The unclean room was finally cleaned!!! and looked beautiful.\",\n",
        "    \"Even the unclean utensils were washed and organized nicely.\",\n",
        "    \"He saw the unclean water but fixed the source quickly.\",\n",
        "    \"The unclean city streets were transformed into green parks.\",\n",
        "    \"Though it was unclean, the area was sanitized with care.\"\n",
        "]\n",
        "\n",
        "negative_sentences = [\n",
        "    \"The unclean bathroom smelled terrible and was unusable.\",\n",
        "    \"Unclean food caused food poisoning at the party.\",\n",
        "    \"She disliked the unclean environment of the hostel.\",\n",
        "    \"The unclean river emitted a foul odor.\",\n",
        "    \"They were disgusted by the unclean conditions in the hotel.\"\n",
        "]\n",
        "\n",
        "sentences = positive_sentences + negative_sentences\n",
        "labels = [1]*5 + [0]*5  # 1 = Positive, 0 = Negative"
      ],
      "metadata": {
        "id": "I2ogVl_50wXp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Preprocessing Function (Lowercase, Remove Punctuation, etc.)\n",
        "def preprocess(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove punctuation\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
        "    return text\n",
        "\n",
        "cleaned_sentences = [preprocess(s) for s in sentences]\n",
        "print(\"\\n--- Cleaned Sentences ---\")\n",
        "for i, s in enumerate(cleaned_sentences):\n",
        "    print(f\"{i+1}. {s}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9g0cejW0wrc",
        "outputId": "ddd21c2d-1cda-482c-b936-56c89763f846"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Cleaned Sentences ---\n",
            "1. the unclean room was finally cleaned and looked beautiful\n",
            "2. even the unclean utensils were washed and organized nicely\n",
            "3. he saw the unclean water but fixed the source quickly\n",
            "4. the unclean city streets were transformed into green parks\n",
            "5. though it was unclean the area was sanitized with care\n",
            "6. the unclean bathroom smelled terrible and was unusable\n",
            "7. unclean food caused food poisoning at the party\n",
            "8. she disliked the unclean environment of the hostel\n",
            "9. the unclean river emitted a foul odor\n",
            "10. they were disgusted by the unclean conditions in the hotel\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Tokenize the Sentences\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(cleaned_sentences)\n",
        "X = tokenizer.texts_to_sequences(cleaned_sentences)\n",
        "\n",
        "# Pad sequences to make them of equal length\n",
        "X = pad_sequences(X, padding='post')"
      ],
      "metadata": {
        "id": "na1_R8zv0xG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Train/Test Split\n",
        "y = np.array(labels)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "XN5lHAaC0xdt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Build the RNN Model with Embedding Layer\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1,  # Vocabulary size\n",
        "                    output_dim=100,  # Embedding dimension\n",
        "                    input_length=X_train.shape[1]))  # Length of input sequences\n",
        "model.add(SimpleRNN(10))  # RNN layer with 10 units\n",
        "model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XR-LH1Zw1MKf",
        "outputId": "14e127b2-2bc2-40e8-9433-07e7694f485b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Compile the Model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "jzF6i6Q21MhC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Train the Model\n",
        "model.fit(X_train, y_train, epochs=5, batch_size=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4w1CEHS1M1v",
        "outputId": "03d65bbd-993f-4b58-88f4-b383df45b335"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.3714 - loss: 0.7201  \n",
            "Epoch 2/5\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.5591 \n",
            "Epoch 3/5\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.4942\n",
            "Epoch 4/5\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.4071\n",
            "Epoch 5/5\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.3379\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c8b32448e50>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Evaluate the Model\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = (y_pred > 0.5).astype(int)  # Convert probabilities to 0/1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0m1vCNha1ZGV",
        "outputId": "258df6ad-e24b-4d62-abc9-7368313a8bc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 522ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. Accuracy\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\n✅ Model Accuracy: {acc:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8kz3Pm61ZdC",
        "outputId": "69ecb281-8062-4b69-cdd8-0f47a22bbabc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Model Accuracy: 0.67\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Fourth"
      ],
      "metadata": {
        "id": "LNkDSVo12YLM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# 1. Example Sentences\n",
        "sentences = [\n",
        "    \"The unclean room was cleaned beautifully.\",\n",
        "    \"She dislikes the unclean environment.\",\n",
        "    \"The river is unclean and polluted in each area.\"\n",
        "]\n",
        "\n",
        "# 2. Tokenization\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(sentences)  # Fit tokenizer on the sentences\n",
        "\n",
        "# 3. Tokenizing the sentences (Converting words to integers)\n",
        "X = tokenizer.texts_to_sequences(sentences)\n",
        "\n",
        "print(\"\\n--- Tokenized Sentences ---\")\n",
        "for i, seq in enumerate(X):\n",
        "    print(f\"Sentence {i+1}: {seq}\")\n",
        "\n",
        "# Output the vocabulary (word -> index mapping)\n",
        "print(\"\\n--- Word Index Mapping ---\")\n",
        "print(tokenizer.word_index)\n",
        "\n",
        "# 4. Padding the sequences\n",
        "X_padded = pad_sequences(X, padding='post')\n",
        "\n",
        "print(\"\\n--- Padded Sequences ---\")\n",
        "for i, seq in enumerate(X_padded):\n",
        "    print(f\"Sentence {i+1} (Padded): {seq}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNxW2Ge81s-x",
        "outputId": "2c2bd729-e424-42d2-ddd0-94c23c4ce3f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Tokenized Sentences ---\n",
            "Sentence 1: [1, 2, 3, 4, 5, 6]\n",
            "Sentence 2: [7, 8, 1, 2, 9]\n",
            "Sentence 3: [1, 10, 11, 2, 12, 13, 14, 15, 16]\n",
            "\n",
            "--- Word Index Mapping ---\n",
            "{'the': 1, 'unclean': 2, 'room': 3, 'was': 4, 'cleaned': 5, 'beautifully': 6, 'she': 7, 'dislikes': 8, 'environment': 9, 'river': 10, 'is': 11, 'and': 12, 'polluted': 13, 'in': 14, 'each': 15, 'area': 16}\n",
            "\n",
            "--- Padded Sequences ---\n",
            "Sentence 1 (Padded): [1 2 3 4 5 6 0 0 0]\n",
            "Sentence 2 (Padded): [7 8 1 2 9 0 0 0 0]\n",
            "Sentence 3 (Padded): [ 1 10 11  2 12 13 14 15 16]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sample Recommendation System"
      ],
      "metadata": {
        "id": "A2tKUN9f2pRM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = {\n",
        "    'title': [\n",
        "        \"The Silent River\", \"Alien Invasion\", \"Love in Paris\", \"Space Explorers\", \"Haunted Memories\",\n",
        "        \"Warrior's Path\", \"Secrets of the Past\", \"The Hacker's Game\", \"Forest of Dreams\", \"Future Code\",\n",
        "        \"The Time Loop\", \"Crimson Dagger\", \"Ocean Depths\", \"Cyber Love\", \"Lost Kingdom\",\n",
        "        \"Comedy Central\", \"Desert Winds\", \"Broken Melody\", \"City Shadows\", \"Dream Catcher\"\n",
        "    ],\n",
        "    'genre': [\n",
        "        \"Drama\", \"Sci-Fi\", \"Romance\", \"Sci-Fi\", \"Horror\",\n",
        "        \"Action\", \"Mystery\", \"Thriller\", \"Fantasy\", \"Sci-Fi\",\n",
        "        \"Sci-Fi\", \"Action\", \"Adventure\", \"Romance\", \"Fantasy\",\n",
        "        \"Comedy\", \"Adventure\", \"Drama\", \"Thriller\", \"Mystery\"\n",
        "    ],\n",
        "    'plot': [\n",
        "        \"A man returns to his hometown and uncovers forgotten memories.\",\n",
        "        \"Aliens attack Earth and humans fight to survive.\",\n",
        "        \"Two strangers fall in love during a trip to Paris.\",\n",
        "        \"Astronauts discover a new planet beyond Mars.\",\n",
        "        \"A woman hears voices in a haunted mansion.\",\n",
        "        \"A warrior seeks revenge for his lost family.\",\n",
        "        \"An old diary reveals shocking secrets from the past.\",\n",
        "        \"A hacker gets trapped in his own virtual creation.\",\n",
        "        \"A girl finds a magical portal in the forest.\",\n",
        "        \"In a tech-driven future, AI begins to rebel.\",\n",
        "        \"A scientist stuck in a time loop tries to fix the past.\",\n",
        "        \"A detective tracks a killer with a crimson dagger.\",\n",
        "        \"Divers find a hidden civilization under the sea.\",\n",
        "        \"Two lovers connect through digital devices.\",\n",
        "        \"A prince must reclaim his lost throne.\",\n",
        "        \"Friends get into hilarious mischief at a comedy club.\",\n",
        "        \"A tribe survives harsh conditions in the desert.\",\n",
        "        \"A musician searches for meaning after a tragic loss.\",\n",
        "        \"A journalist uncovers secrets in a corrupted city.\",\n",
        "        \"Teenagers enter dreams to fight their fears.\"\n",
        "    ],\n",
        "    'director_actors': [\n",
        "        \"John Doe, Emily Stone\", \"Sarah Lynn, Tom Cruise\", \"Alex Wright, Julia Roberts\", \"Nolan Pierce, Chris Pratt\",\n",
        "        \"Lisa Holmes, Kate Winslet\", \"Dan Moore, Jason Momoa\", \"Mira Lee, Rachel McAdams\", \"Tom Hanks, Ava Green\",\n",
        "        \"Jackie Chan, Emma Watson\", \"Rob Lowe, Emma Stone\", \"Mark Ruffalo, Keira Knightley\", \"David Fincher, Brad Pitt\",\n",
        "        \"Sophie Turner, Leonardo DiCaprio\", \"Emma Thompson, Ryan Gosling\", \"Chris Evans, Natalie Portman\",\n",
        "        \"Ben Stiller, Adam Sandler\", \"Angelina Jolie, Rami Malek\", \"Lady Gaga, Hugh Jackman\", \"Morgan Freeman, Anne Hathaway\",\n",
        "        \"Millie Bobby Brown, Noah Schnapp\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "tpKMiu6j1tTX",
        "outputId": "fa86877e-dffa-432a-e9d8-7c0472c7a1c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  title      genre  \\\n",
              "0      The Silent River      Drama   \n",
              "1        Alien Invasion     Sci-Fi   \n",
              "2         Love in Paris    Romance   \n",
              "3       Space Explorers     Sci-Fi   \n",
              "4      Haunted Memories     Horror   \n",
              "5        Warrior's Path     Action   \n",
              "6   Secrets of the Past    Mystery   \n",
              "7     The Hacker's Game   Thriller   \n",
              "8      Forest of Dreams    Fantasy   \n",
              "9           Future Code     Sci-Fi   \n",
              "10        The Time Loop     Sci-Fi   \n",
              "11       Crimson Dagger     Action   \n",
              "12         Ocean Depths  Adventure   \n",
              "13           Cyber Love    Romance   \n",
              "14         Lost Kingdom    Fantasy   \n",
              "15       Comedy Central     Comedy   \n",
              "16         Desert Winds  Adventure   \n",
              "17        Broken Melody      Drama   \n",
              "18         City Shadows   Thriller   \n",
              "19        Dream Catcher    Mystery   \n",
              "\n",
              "                                                 plot  \\\n",
              "0   A man returns to his hometown and uncovers for...   \n",
              "1    Aliens attack Earth and humans fight to survive.   \n",
              "2   Two strangers fall in love during a trip to Pa...   \n",
              "3       Astronauts discover a new planet beyond Mars.   \n",
              "4          A woman hears voices in a haunted mansion.   \n",
              "5        A warrior seeks revenge for his lost family.   \n",
              "6   An old diary reveals shocking secrets from the...   \n",
              "7   A hacker gets trapped in his own virtual creat...   \n",
              "8        A girl finds a magical portal in the forest.   \n",
              "9        In a tech-driven future, AI begins to rebel.   \n",
              "10  A scientist stuck in a time loop tries to fix ...   \n",
              "11  A detective tracks a killer with a crimson dag...   \n",
              "12   Divers find a hidden civilization under the sea.   \n",
              "13        Two lovers connect through digital devices.   \n",
              "14             A prince must reclaim his lost throne.   \n",
              "15  Friends get into hilarious mischief at a comed...   \n",
              "16   A tribe survives harsh conditions in the desert.   \n",
              "17  A musician searches for meaning after a tragic...   \n",
              "18  A journalist uncovers secrets in a corrupted c...   \n",
              "19       Teenagers enter dreams to fight their fears.   \n",
              "\n",
              "                     director_actors  \n",
              "0              John Doe, Emily Stone  \n",
              "1             Sarah Lynn, Tom Cruise  \n",
              "2         Alex Wright, Julia Roberts  \n",
              "3          Nolan Pierce, Chris Pratt  \n",
              "4          Lisa Holmes, Kate Winslet  \n",
              "5             Dan Moore, Jason Momoa  \n",
              "6           Mira Lee, Rachel McAdams  \n",
              "7               Tom Hanks, Ava Green  \n",
              "8           Jackie Chan, Emma Watson  \n",
              "9               Rob Lowe, Emma Stone  \n",
              "10     Mark Ruffalo, Keira Knightley  \n",
              "11          David Fincher, Brad Pitt  \n",
              "12  Sophie Turner, Leonardo DiCaprio  \n",
              "13       Emma Thompson, Ryan Gosling  \n",
              "14      Chris Evans, Natalie Portman  \n",
              "15         Ben Stiller, Adam Sandler  \n",
              "16        Angelina Jolie, Rami Malek  \n",
              "17           Lady Gaga, Hugh Jackman  \n",
              "18     Morgan Freeman, Anne Hathaway  \n",
              "19  Millie Bobby Brown, Noah Schnapp  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5a0f9d72-cea9-4bf6-b32d-4b2176e60009\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>genre</th>\n",
              "      <th>plot</th>\n",
              "      <th>director_actors</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The Silent River</td>\n",
              "      <td>Drama</td>\n",
              "      <td>A man returns to his hometown and uncovers for...</td>\n",
              "      <td>John Doe, Emily Stone</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Alien Invasion</td>\n",
              "      <td>Sci-Fi</td>\n",
              "      <td>Aliens attack Earth and humans fight to survive.</td>\n",
              "      <td>Sarah Lynn, Tom Cruise</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Love in Paris</td>\n",
              "      <td>Romance</td>\n",
              "      <td>Two strangers fall in love during a trip to Pa...</td>\n",
              "      <td>Alex Wright, Julia Roberts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Space Explorers</td>\n",
              "      <td>Sci-Fi</td>\n",
              "      <td>Astronauts discover a new planet beyond Mars.</td>\n",
              "      <td>Nolan Pierce, Chris Pratt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Haunted Memories</td>\n",
              "      <td>Horror</td>\n",
              "      <td>A woman hears voices in a haunted mansion.</td>\n",
              "      <td>Lisa Holmes, Kate Winslet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Warrior's Path</td>\n",
              "      <td>Action</td>\n",
              "      <td>A warrior seeks revenge for his lost family.</td>\n",
              "      <td>Dan Moore, Jason Momoa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Secrets of the Past</td>\n",
              "      <td>Mystery</td>\n",
              "      <td>An old diary reveals shocking secrets from the...</td>\n",
              "      <td>Mira Lee, Rachel McAdams</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>The Hacker's Game</td>\n",
              "      <td>Thriller</td>\n",
              "      <td>A hacker gets trapped in his own virtual creat...</td>\n",
              "      <td>Tom Hanks, Ava Green</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Forest of Dreams</td>\n",
              "      <td>Fantasy</td>\n",
              "      <td>A girl finds a magical portal in the forest.</td>\n",
              "      <td>Jackie Chan, Emma Watson</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Future Code</td>\n",
              "      <td>Sci-Fi</td>\n",
              "      <td>In a tech-driven future, AI begins to rebel.</td>\n",
              "      <td>Rob Lowe, Emma Stone</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>The Time Loop</td>\n",
              "      <td>Sci-Fi</td>\n",
              "      <td>A scientist stuck in a time loop tries to fix ...</td>\n",
              "      <td>Mark Ruffalo, Keira Knightley</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Crimson Dagger</td>\n",
              "      <td>Action</td>\n",
              "      <td>A detective tracks a killer with a crimson dag...</td>\n",
              "      <td>David Fincher, Brad Pitt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Ocean Depths</td>\n",
              "      <td>Adventure</td>\n",
              "      <td>Divers find a hidden civilization under the sea.</td>\n",
              "      <td>Sophie Turner, Leonardo DiCaprio</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Cyber Love</td>\n",
              "      <td>Romance</td>\n",
              "      <td>Two lovers connect through digital devices.</td>\n",
              "      <td>Emma Thompson, Ryan Gosling</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Lost Kingdom</td>\n",
              "      <td>Fantasy</td>\n",
              "      <td>A prince must reclaim his lost throne.</td>\n",
              "      <td>Chris Evans, Natalie Portman</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Comedy Central</td>\n",
              "      <td>Comedy</td>\n",
              "      <td>Friends get into hilarious mischief at a comed...</td>\n",
              "      <td>Ben Stiller, Adam Sandler</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Desert Winds</td>\n",
              "      <td>Adventure</td>\n",
              "      <td>A tribe survives harsh conditions in the desert.</td>\n",
              "      <td>Angelina Jolie, Rami Malek</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Broken Melody</td>\n",
              "      <td>Drama</td>\n",
              "      <td>A musician searches for meaning after a tragic...</td>\n",
              "      <td>Lady Gaga, Hugh Jackman</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>City Shadows</td>\n",
              "      <td>Thriller</td>\n",
              "      <td>A journalist uncovers secrets in a corrupted c...</td>\n",
              "      <td>Morgan Freeman, Anne Hathaway</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Dream Catcher</td>\n",
              "      <td>Mystery</td>\n",
              "      <td>Teenagers enter dreams to fight their fears.</td>\n",
              "      <td>Millie Bobby Brown, Noah Schnapp</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5a0f9d72-cea9-4bf6-b32d-4b2176e60009')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5a0f9d72-cea9-4bf6-b32d-4b2176e60009 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5a0f9d72-cea9-4bf6-b32d-4b2176e60009');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-8721a4c5-409f-40b3-bd9d-a5816c5cf483\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8721a4c5-409f-40b3-bd9d-a5816c5cf483')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-8721a4c5-409f-40b3-bd9d-a5816c5cf483 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_f0992b47-ee40-4de9-8a87-4155938d790b\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f0992b47-ee40-4de9-8a87-4155938d790b button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"The Silent River\",\n          \"Broken Melody\",\n          \"Comedy Central\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"genre\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Adventure\",\n          \"Sci-Fi\",\n          \"Mystery\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"plot\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"A man returns to his hometown and uncovers forgotten memories.\",\n          \"A musician searches for meaning after a tragic loss.\",\n          \"Friends get into hilarious mischief at a comedy club.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"director_actors\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"John Doe, Emily Stone\",\n          \"Lady Gaga, Hugh Jackman\",\n          \"Ben Stiller, Adam Sandler\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    tokens = [stemmer.stem(word) for word in tokens if word not in stop_words]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# Combine all text columns\n",
        "df['combined_text'] = df['genre'] + \" \" + df['plot'] + \" \" + df['director_actors']\n",
        "df['processed'] = df['combined_text'].apply(preprocess_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JV7-9VRm1tog",
        "outputId": "62f29109-bbca-4037-ce92-e97c0576b71d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 936
        },
        "id": "NHk-ukrR1t6u",
        "outputId": "e0f584e9-67a9-48b1-d6ec-d453fca2e344"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  title      genre  \\\n",
              "0      The Silent River      Drama   \n",
              "1        Alien Invasion     Sci-Fi   \n",
              "2         Love in Paris    Romance   \n",
              "3       Space Explorers     Sci-Fi   \n",
              "4      Haunted Memories     Horror   \n",
              "5        Warrior's Path     Action   \n",
              "6   Secrets of the Past    Mystery   \n",
              "7     The Hacker's Game   Thriller   \n",
              "8      Forest of Dreams    Fantasy   \n",
              "9           Future Code     Sci-Fi   \n",
              "10        The Time Loop     Sci-Fi   \n",
              "11       Crimson Dagger     Action   \n",
              "12         Ocean Depths  Adventure   \n",
              "13           Cyber Love    Romance   \n",
              "14         Lost Kingdom    Fantasy   \n",
              "15       Comedy Central     Comedy   \n",
              "16         Desert Winds  Adventure   \n",
              "17        Broken Melody      Drama   \n",
              "18         City Shadows   Thriller   \n",
              "19        Dream Catcher    Mystery   \n",
              "\n",
              "                                                 plot  \\\n",
              "0   A man returns to his hometown and uncovers for...   \n",
              "1    Aliens attack Earth and humans fight to survive.   \n",
              "2   Two strangers fall in love during a trip to Pa...   \n",
              "3       Astronauts discover a new planet beyond Mars.   \n",
              "4          A woman hears voices in a haunted mansion.   \n",
              "5        A warrior seeks revenge for his lost family.   \n",
              "6   An old diary reveals shocking secrets from the...   \n",
              "7   A hacker gets trapped in his own virtual creat...   \n",
              "8        A girl finds a magical portal in the forest.   \n",
              "9        In a tech-driven future, AI begins to rebel.   \n",
              "10  A scientist stuck in a time loop tries to fix ...   \n",
              "11  A detective tracks a killer with a crimson dag...   \n",
              "12   Divers find a hidden civilization under the sea.   \n",
              "13        Two lovers connect through digital devices.   \n",
              "14             A prince must reclaim his lost throne.   \n",
              "15  Friends get into hilarious mischief at a comed...   \n",
              "16   A tribe survives harsh conditions in the desert.   \n",
              "17  A musician searches for meaning after a tragic...   \n",
              "18  A journalist uncovers secrets in a corrupted c...   \n",
              "19       Teenagers enter dreams to fight their fears.   \n",
              "\n",
              "                     director_actors  \\\n",
              "0              John Doe, Emily Stone   \n",
              "1             Sarah Lynn, Tom Cruise   \n",
              "2         Alex Wright, Julia Roberts   \n",
              "3          Nolan Pierce, Chris Pratt   \n",
              "4          Lisa Holmes, Kate Winslet   \n",
              "5             Dan Moore, Jason Momoa   \n",
              "6           Mira Lee, Rachel McAdams   \n",
              "7               Tom Hanks, Ava Green   \n",
              "8           Jackie Chan, Emma Watson   \n",
              "9               Rob Lowe, Emma Stone   \n",
              "10     Mark Ruffalo, Keira Knightley   \n",
              "11          David Fincher, Brad Pitt   \n",
              "12  Sophie Turner, Leonardo DiCaprio   \n",
              "13       Emma Thompson, Ryan Gosling   \n",
              "14      Chris Evans, Natalie Portman   \n",
              "15         Ben Stiller, Adam Sandler   \n",
              "16        Angelina Jolie, Rami Malek   \n",
              "17           Lady Gaga, Hugh Jackman   \n",
              "18     Morgan Freeman, Anne Hathaway   \n",
              "19  Millie Bobby Brown, Noah Schnapp   \n",
              "\n",
              "                                        combined_text  \\\n",
              "0   Drama A man returns to his hometown and uncove...   \n",
              "1   Sci-Fi Aliens attack Earth and humans fight to...   \n",
              "2   Romance Two strangers fall in love during a tr...   \n",
              "3   Sci-Fi Astronauts discover a new planet beyond...   \n",
              "4   Horror A woman hears voices in a haunted mansi...   \n",
              "5   Action A warrior seeks revenge for his lost fa...   \n",
              "6   Mystery An old diary reveals shocking secrets ...   \n",
              "7   Thriller A hacker gets trapped in his own virt...   \n",
              "8   Fantasy A girl finds a magical portal in the f...   \n",
              "9   Sci-Fi In a tech-driven future, AI begins to r...   \n",
              "10  Sci-Fi A scientist stuck in a time loop tries ...   \n",
              "11  Action A detective tracks a killer with a crim...   \n",
              "12  Adventure Divers find a hidden civilization un...   \n",
              "13  Romance Two lovers connect through digital dev...   \n",
              "14  Fantasy A prince must reclaim his lost throne....   \n",
              "15  Comedy Friends get into hilarious mischief at ...   \n",
              "16  Adventure A tribe survives harsh conditions in...   \n",
              "17  Drama A musician searches for meaning after a ...   \n",
              "18  Thriller A journalist uncovers secrets in a co...   \n",
              "19  Mystery Teenagers enter dreams to fight their ...   \n",
              "\n",
              "                                            processed  \n",
              "0   drama man return hometown uncov forgotten memo...  \n",
              "1   scifi alien attack earth human fight surviv sa...  \n",
              "2   romanc two stranger fall love trip pari alex w...  \n",
              "3   scifi astronaut discov new planet beyond mar n...  \n",
              "4   horror woman hear voic haunt mansion lisa holm...  \n",
              "5   action warrior seek reveng lost famili dan moo...  \n",
              "6   mysteri old diari reveal shock secret past mir...  \n",
              "7   thriller hacker get trap virtual creation tom ...  \n",
              "8   fantasi girl find magic portal forest jacki ch...  \n",
              "9   scifi techdriven futur ai begin rebel rob low ...  \n",
              "10  scifi scientist stuck time loop tri fix past m...  \n",
              "11  action detect track killer crimson dagger davi...  \n",
              "12  adventur diver find hidden civil sea sophi tur...  \n",
              "13  romanc two lover connect digit devic emma thom...  \n",
              "14  fantasi princ must reclaim lost throne chri ev...  \n",
              "15  comedi friend get hilari mischief comedi club ...  \n",
              "16  adventur tribe surviv harsh condit desert ange...  \n",
              "17  drama musician search mean tragic loss ladi ga...  \n",
              "18  thriller journalist uncov secret corrupt citi ...  \n",
              "19  mysteri teenag enter dream fight fear milli bo...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-96021fce-4081-40d3-a4a5-42e4b96f47db\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>genre</th>\n",
              "      <th>plot</th>\n",
              "      <th>director_actors</th>\n",
              "      <th>combined_text</th>\n",
              "      <th>processed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The Silent River</td>\n",
              "      <td>Drama</td>\n",
              "      <td>A man returns to his hometown and uncovers for...</td>\n",
              "      <td>John Doe, Emily Stone</td>\n",
              "      <td>Drama A man returns to his hometown and uncove...</td>\n",
              "      <td>drama man return hometown uncov forgotten memo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Alien Invasion</td>\n",
              "      <td>Sci-Fi</td>\n",
              "      <td>Aliens attack Earth and humans fight to survive.</td>\n",
              "      <td>Sarah Lynn, Tom Cruise</td>\n",
              "      <td>Sci-Fi Aliens attack Earth and humans fight to...</td>\n",
              "      <td>scifi alien attack earth human fight surviv sa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Love in Paris</td>\n",
              "      <td>Romance</td>\n",
              "      <td>Two strangers fall in love during a trip to Pa...</td>\n",
              "      <td>Alex Wright, Julia Roberts</td>\n",
              "      <td>Romance Two strangers fall in love during a tr...</td>\n",
              "      <td>romanc two stranger fall love trip pari alex w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Space Explorers</td>\n",
              "      <td>Sci-Fi</td>\n",
              "      <td>Astronauts discover a new planet beyond Mars.</td>\n",
              "      <td>Nolan Pierce, Chris Pratt</td>\n",
              "      <td>Sci-Fi Astronauts discover a new planet beyond...</td>\n",
              "      <td>scifi astronaut discov new planet beyond mar n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Haunted Memories</td>\n",
              "      <td>Horror</td>\n",
              "      <td>A woman hears voices in a haunted mansion.</td>\n",
              "      <td>Lisa Holmes, Kate Winslet</td>\n",
              "      <td>Horror A woman hears voices in a haunted mansi...</td>\n",
              "      <td>horror woman hear voic haunt mansion lisa holm...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Warrior's Path</td>\n",
              "      <td>Action</td>\n",
              "      <td>A warrior seeks revenge for his lost family.</td>\n",
              "      <td>Dan Moore, Jason Momoa</td>\n",
              "      <td>Action A warrior seeks revenge for his lost fa...</td>\n",
              "      <td>action warrior seek reveng lost famili dan moo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Secrets of the Past</td>\n",
              "      <td>Mystery</td>\n",
              "      <td>An old diary reveals shocking secrets from the...</td>\n",
              "      <td>Mira Lee, Rachel McAdams</td>\n",
              "      <td>Mystery An old diary reveals shocking secrets ...</td>\n",
              "      <td>mysteri old diari reveal shock secret past mir...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>The Hacker's Game</td>\n",
              "      <td>Thriller</td>\n",
              "      <td>A hacker gets trapped in his own virtual creat...</td>\n",
              "      <td>Tom Hanks, Ava Green</td>\n",
              "      <td>Thriller A hacker gets trapped in his own virt...</td>\n",
              "      <td>thriller hacker get trap virtual creation tom ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Forest of Dreams</td>\n",
              "      <td>Fantasy</td>\n",
              "      <td>A girl finds a magical portal in the forest.</td>\n",
              "      <td>Jackie Chan, Emma Watson</td>\n",
              "      <td>Fantasy A girl finds a magical portal in the f...</td>\n",
              "      <td>fantasi girl find magic portal forest jacki ch...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Future Code</td>\n",
              "      <td>Sci-Fi</td>\n",
              "      <td>In a tech-driven future, AI begins to rebel.</td>\n",
              "      <td>Rob Lowe, Emma Stone</td>\n",
              "      <td>Sci-Fi In a tech-driven future, AI begins to r...</td>\n",
              "      <td>scifi techdriven futur ai begin rebel rob low ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>The Time Loop</td>\n",
              "      <td>Sci-Fi</td>\n",
              "      <td>A scientist stuck in a time loop tries to fix ...</td>\n",
              "      <td>Mark Ruffalo, Keira Knightley</td>\n",
              "      <td>Sci-Fi A scientist stuck in a time loop tries ...</td>\n",
              "      <td>scifi scientist stuck time loop tri fix past m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Crimson Dagger</td>\n",
              "      <td>Action</td>\n",
              "      <td>A detective tracks a killer with a crimson dag...</td>\n",
              "      <td>David Fincher, Brad Pitt</td>\n",
              "      <td>Action A detective tracks a killer with a crim...</td>\n",
              "      <td>action detect track killer crimson dagger davi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Ocean Depths</td>\n",
              "      <td>Adventure</td>\n",
              "      <td>Divers find a hidden civilization under the sea.</td>\n",
              "      <td>Sophie Turner, Leonardo DiCaprio</td>\n",
              "      <td>Adventure Divers find a hidden civilization un...</td>\n",
              "      <td>adventur diver find hidden civil sea sophi tur...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Cyber Love</td>\n",
              "      <td>Romance</td>\n",
              "      <td>Two lovers connect through digital devices.</td>\n",
              "      <td>Emma Thompson, Ryan Gosling</td>\n",
              "      <td>Romance Two lovers connect through digital dev...</td>\n",
              "      <td>romanc two lover connect digit devic emma thom...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Lost Kingdom</td>\n",
              "      <td>Fantasy</td>\n",
              "      <td>A prince must reclaim his lost throne.</td>\n",
              "      <td>Chris Evans, Natalie Portman</td>\n",
              "      <td>Fantasy A prince must reclaim his lost throne....</td>\n",
              "      <td>fantasi princ must reclaim lost throne chri ev...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Comedy Central</td>\n",
              "      <td>Comedy</td>\n",
              "      <td>Friends get into hilarious mischief at a comed...</td>\n",
              "      <td>Ben Stiller, Adam Sandler</td>\n",
              "      <td>Comedy Friends get into hilarious mischief at ...</td>\n",
              "      <td>comedi friend get hilari mischief comedi club ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Desert Winds</td>\n",
              "      <td>Adventure</td>\n",
              "      <td>A tribe survives harsh conditions in the desert.</td>\n",
              "      <td>Angelina Jolie, Rami Malek</td>\n",
              "      <td>Adventure A tribe survives harsh conditions in...</td>\n",
              "      <td>adventur tribe surviv harsh condit desert ange...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Broken Melody</td>\n",
              "      <td>Drama</td>\n",
              "      <td>A musician searches for meaning after a tragic...</td>\n",
              "      <td>Lady Gaga, Hugh Jackman</td>\n",
              "      <td>Drama A musician searches for meaning after a ...</td>\n",
              "      <td>drama musician search mean tragic loss ladi ga...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>City Shadows</td>\n",
              "      <td>Thriller</td>\n",
              "      <td>A journalist uncovers secrets in a corrupted c...</td>\n",
              "      <td>Morgan Freeman, Anne Hathaway</td>\n",
              "      <td>Thriller A journalist uncovers secrets in a co...</td>\n",
              "      <td>thriller journalist uncov secret corrupt citi ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Dream Catcher</td>\n",
              "      <td>Mystery</td>\n",
              "      <td>Teenagers enter dreams to fight their fears.</td>\n",
              "      <td>Millie Bobby Brown, Noah Schnapp</td>\n",
              "      <td>Mystery Teenagers enter dreams to fight their ...</td>\n",
              "      <td>mysteri teenag enter dream fight fear milli bo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-96021fce-4081-40d3-a4a5-42e4b96f47db')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-96021fce-4081-40d3-a4a5-42e4b96f47db button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-96021fce-4081-40d3-a4a5-42e4b96f47db');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-0950cfa2-af5c-4778-9a34-45f2aeeb9771\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0950cfa2-af5c-4778-9a34-45f2aeeb9771')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-0950cfa2-af5c-4778-9a34-45f2aeeb9771 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_3339c039-310f-4a2b-80e8-f3de77434c4f\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_3339c039-310f-4a2b-80e8-f3de77434c4f button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"The Silent River\",\n          \"Broken Melody\",\n          \"Comedy Central\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"genre\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Adventure\",\n          \"Sci-Fi\",\n          \"Mystery\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"plot\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"A man returns to his hometown and uncovers forgotten memories.\",\n          \"A musician searches for meaning after a tragic loss.\",\n          \"Friends get into hilarious mischief at a comedy club.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"director_actors\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"John Doe, Emily Stone\",\n          \"Lady Gaga, Hugh Jackman\",\n          \"Ben Stiller, Adam Sandler\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"combined_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"Drama A man returns to his hometown and uncovers forgotten memories. John Doe, Emily Stone\",\n          \"Drama A musician searches for meaning after a tragic loss. Lady Gaga, Hugh Jackman\",\n          \"Comedy Friends get into hilarious mischief at a comedy club. Ben Stiller, Adam Sandler\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"processed\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"drama man return hometown uncov forgotten memori john doe emili stone\",\n          \"drama musician search mean tragic loss ladi gaga hugh jackman\",\n          \"comedi friend get hilari mischief comedi club ben stiller adam sandler\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['combined_text'][0])\n",
        "print(df['processed'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EeymgN6R3NrE",
        "outputId": "244ab92e-c2e3-418f-c8d6-1f7955b99c19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drama A man returns to his hometown and uncovers forgotten memories. John Doe, Emily Stone\n",
            "drama man return hometown uncov forgotten memori john doe emili stone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['combined_text'][5])\n",
        "print(df['processed'][5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBbovOmC3OAJ",
        "outputId": "0c909d0b-a520-4254-f07b-83bce80a6275"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Action A warrior seeks revenge for his lost family. Dan Moore, Jason Momoa\n",
            "action warrior seek reveng lost famili dan moor jason momoa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf = TfidfVectorizer()\n",
        "tfidf_matrix = tfidf.fit_transform(df['processed'])\n",
        "\n",
        "# Show TF-IDF vector for first movie\n",
        "print(\"TF-IDF vector for:\", df['title'][0])\n",
        "print(tfidf_matrix[0].toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_3Etx0B3OVL",
        "outputId": "7a58e5d8-6f05-4210-d614-14e6ac189011"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF vector for: The Silent River\n",
            "[[0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.31131651 0.27365198\n",
            "  0.         0.         0.31131651 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.31131651 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.31131651 0.         0.\n",
            "  0.         0.         0.         0.         0.31131651 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.31131651 0.         0.         0.         0.\n",
            "  0.         0.31131651 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.31131651\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.27365198 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.27365198 0.         0.         0.\n",
            "  0.         0.         0.         0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_matrix[0].toarray().shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnCPCNR13ez6",
        "outputId": "9354e894-2de9-48a9-838c-f06c3b7f66fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 184)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "import numpy as np\n",
        "\n",
        "# Tokenize for Word2Vec\n",
        "tokenized = df['processed'].apply(lambda x: x.split())\n",
        "model_w2v = Word2Vec(tokenized, vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "def get_avg_vector(words, model):\n",
        "    valid_words = [w for w in words if w in model.wv]\n",
        "    if not valid_words:\n",
        "        return np.zeros(model.vector_size)\n",
        "    return np.mean(model.wv[valid_words], axis=0)\n",
        "\n",
        "# Apply for all\n",
        "w2v_vectors = np.array([get_avg_vector(words, model_w2v) for words in tokenized])\n",
        "\n",
        "# Show Word2Vec vector\n",
        "print(\"Word2Vec vector for:\", df['title'][0])\n",
        "print(w2v_vectors[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmXGNe383fE0",
        "outputId": "410787b5-8d68-459d-cf7a-1dabcff56a22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word2Vec vector for: The Silent River\n",
            "[-3.3739445e-05  2.6075786e-03  1.5648683e-04  2.8222130e-04\n",
            "  1.1263975e-03 -1.3805124e-03  5.7964669e-05  2.3657011e-03\n",
            "  2.4490631e-03  1.3327668e-03 -1.0642976e-03  4.5006213e-04\n",
            "  1.4781873e-03  8.1299600e-04  3.0081607e-03 -2.9666006e-04\n",
            " -1.2521633e-03  9.5451024e-04  1.5424583e-03  6.3802360e-04\n",
            " -1.7164796e-04  1.2884001e-05 -6.0166628e-04  1.0123043e-03\n",
            " -5.0504785e-04  2.1072591e-03 -5.5997074e-04 -1.2554459e-03\n",
            "  4.4413824e-03  7.4270146e-04  5.9308769e-04 -2.1500478e-03\n",
            " -1.1702656e-03  2.1319874e-03 -1.8855922e-03 -3.2735858e-04\n",
            "  1.2311161e-03 -2.1405129e-03  1.3628964e-03 -2.1349073e-03\n",
            " -2.4220334e-04  6.2747567e-04  4.0217338e-04 -2.2907197e-03\n",
            " -3.8146516e-03  6.6526751e-05 -1.5009635e-03 -8.8208145e-04\n",
            "  1.5917864e-03  9.1721700e-04 -3.1184768e-03 -2.3731560e-04\n",
            " -1.3497178e-03 -5.4171577e-04  1.9906035e-03  2.6070487e-03\n",
            "  1.8991376e-03 -2.7686320e-04  1.4657431e-03 -1.3278122e-03\n",
            "  9.2533644e-04  6.9781468e-04 -1.4420395e-03 -1.7124317e-03\n",
            " -7.2331238e-04  9.2924759e-04  5.3805677e-04 -5.2402599e-04\n",
            " -2.2503065e-03  2.3827597e-03  3.8336244e-04 -1.5333940e-03\n",
            " -9.1514277e-04  4.3926237e-04 -7.2117127e-04  9.2396891e-04\n",
            " -7.3999260e-04  3.3636778e-03 -2.8048849e-03  8.5213908e-04\n",
            "  6.1427034e-04 -3.1927242e-03 -1.8829603e-03  1.0823718e-03\n",
            " -1.4107988e-03  4.1472947e-04 -1.1651239e-03 -6.3093775e-04\n",
            "  2.5218233e-04 -1.8624351e-03  2.4979478e-03 -2.4590611e-03\n",
            "  1.2415866e-04  2.2903353e-03  5.3437916e-04 -1.1123869e-03\n",
            "  2.3202387e-04  6.9918943e-04 -1.2645962e-03  4.2420326e-04]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def recommend_movies(user_input, vector_type='tfidf', top_n=3):\n",
        "    input_processed = preprocess_text(user_input)\n",
        "\n",
        "    if vector_type == 'tfidf':\n",
        "        input_vec = tfidf.transform([input_processed])\n",
        "        sims = cosine_similarity(input_vec, tfidf_matrix)[0]\n",
        "    else:\n",
        "        input_vec = get_avg_vector(input_processed.split(), model_w2v).reshape(1, -1)\n",
        "        sims = cosine_similarity(input_vec, w2v_vectors)[0]\n",
        "\n",
        "    top_idx = sims.argsort()[-top_n:][::-1]\n",
        "    for idx in top_idx:\n",
        "        print(f\"{df['title'][idx]} (Score: {sims[idx]:.2f})\")\n",
        "\n",
        "# Try it out\n",
        "user_input = \"Time travel scientist\"\n",
        "print(\"\\n🔍 Recommendations using TF-IDF:\")\n",
        "recommend_movies(user_input, vector_type='tfidf')\n",
        "\n",
        "print(\"\\n🔍 Recommendations using Word2Vec:\")\n",
        "recommend_movies(user_input, vector_type='w2v')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bns9hdu33fcw",
        "outputId": "058dbab0-cd2a-4b2c-e671-e458e6a45d1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 Recommendations using TF-IDF:\n",
            "The Time Loop (Score: 0.42)\n",
            "Dream Catcher (Score: 0.00)\n",
            "Forest of Dreams (Score: 0.00)\n",
            "\n",
            "🔍 Recommendations using Word2Vec:\n",
            "The Time Loop (Score: 0.25)\n",
            "Warrior's Path (Score: 0.15)\n",
            "Space Explorers (Score: 0.15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Predicting Next Words"
      ],
      "metadata": {
        "id": "RKqUmnmU3wfz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense"
      ],
      "metadata": {
        "id": "nRgh7hXQ3tbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = [\n",
        "    \"the sun rises in the east\",\n",
        "    \"the moon shines at night\",\n",
        "    \"the stars twinkle in the sky\",\n",
        "    \"the sun sets in the west\",\n",
        "    \"the sky is blue and vast\",\n",
        "    \"the night is dark and quiet\",\n",
        "    \"the stars shine brightly at night\",\n",
        "    \"the children play in the park\",\n",
        "    \"the dog barked loudly at strangers\",\n",
        "    \"the cat sleeps on the couch\",\n",
        "    \"the boy reads a book every day\",\n",
        "    \"the girl sings a beautiful song\",\n",
        "    \"the bird flies in the sky\",\n",
        "    \"the wind blows gently at night\",\n",
        "    \"the rain falls on the roof\",\n",
        "    \"the flowers bloom in spring\",\n",
        "    \"the trees sway in the wind\",\n",
        "    \"the baby smiles at her mother\",\n",
        "    \"the teacher writes on the board\",\n",
        "    \"the students listen to the lesson\",\n",
        "]"
      ],
      "metadata": {
        "id": "AclxDx_D3t_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "total_words = len(tokenizer.word_index) + 1  # +1 for padding\n",
        "print(\"Total words:\", total_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SctqTjtK38CT",
        "outputId": "eed0bcc2-b481-4a5f-bb10-601862f1cf02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total words: 68\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create input sequences (1 to n)\n",
        "input_sequences = []\n",
        "for line in corpus:\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0] # [[1, 2, 3]] [0] returns [1,2,3]\n",
        "    for i in range(1, len(token_list)):\n",
        "        n_gram_seq = token_list[:i+1]\n",
        "        input_sequences.append(n_gram_seq)"
      ],
      "metadata": {
        "id": "mrOpYl5L38fR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pad sequences\n",
        "max_seq_len = max([len(seq) for seq in input_sequences])\n",
        "input_sequences = pad_sequences(input_sequences, maxlen=max_seq_len, padding='pre')\n"
      ],
      "metadata": {
        "id": "_u78vA5_380H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split predictors and label\n",
        "X = input_sequences[:, :-1]\n",
        "y = input_sequences[:, -1]\n",
        "y = to_categorical(y, num_classes=total_words)"
      ],
      "metadata": {
        "id": "DDoVfW4G4JZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define LSTM model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=total_words, output_dim=10, input_length=max_seq_len-1))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "id": "3dZ1qIfx4Jqt",
        "outputId": "117a6f80-033a-43ce-fcbb-b1af25405f73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "model.fit(X, y, epochs=200, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9qOqjc64O2k",
        "outputId": "92394372-254f-4444-a524-c8b269a54a8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.0061 - loss: 4.2194   \n",
            "Epoch 2/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0865 - loss: 4.2143\n",
            "Epoch 3/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0800 - loss: 4.2107\n",
            "Epoch 4/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1081 - loss: 4.2060\n",
            "Epoch 5/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0998 - loss: 4.2009\n",
            "Epoch 6/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1269 - loss: 4.1920\n",
            "Epoch 7/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0987 - loss: 4.1792\n",
            "Epoch 8/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1081 - loss: 4.1664\n",
            "Epoch 9/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1112 - loss: 4.1420\n",
            "Epoch 10/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1206 - loss: 4.1148\n",
            "Epoch 11/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1060 - loss: 4.0686\n",
            "Epoch 12/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0894 - loss: 3.9955\n",
            "Epoch 13/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0748 - loss: 3.9646\n",
            "Epoch 14/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.1123 - loss: 3.9520\n",
            "Epoch 15/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0998 - loss: 3.9498\n",
            "Epoch 16/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0977 - loss: 4.0009\n",
            "Epoch 17/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1237 - loss: 3.8934\n",
            "Epoch 18/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.1112 - loss: 3.9409\n",
            "Epoch 19/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0946 - loss: 3.9550\n",
            "Epoch 20/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.1279 - loss: 3.9191\n",
            "Epoch 21/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1269 - loss: 3.8464\n",
            "Epoch 22/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1019 - loss: 3.9290\n",
            "Epoch 23/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0894 - loss: 3.9262\n",
            "Epoch 24/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.1029 - loss: 3.9064\n",
            "Epoch 25/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0925 - loss: 3.9348\n",
            "Epoch 26/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1050 - loss: 3.8615\n",
            "Epoch 27/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1185 - loss: 3.8107\n",
            "Epoch 28/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1092 - loss: 3.8777\n",
            "Epoch 29/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0842 - loss: 3.8904\n",
            "Epoch 30/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0842 - loss: 3.9001\n",
            "Epoch 31/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.1112 - loss: 3.8244\n",
            "Epoch 32/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0842 - loss: 3.8606\n",
            "Epoch 33/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0998 - loss: 3.7746\n",
            "Epoch 34/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.1081 - loss: 3.7980\n",
            "Epoch 35/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.1185 - loss: 3.7935\n",
            "Epoch 36/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0977 - loss: 3.7636\n",
            "Epoch 37/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0987 - loss: 3.7655\n",
            "Epoch 38/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0956 - loss: 3.7786\n",
            "Epoch 39/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0831 - loss: 3.8030\n",
            "Epoch 40/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0789 - loss: 3.7880\n",
            "Epoch 41/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0925 - loss: 3.7086\n",
            "Epoch 42/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1081 - loss: 3.6358\n",
            "Epoch 43/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1008 - loss: 3.6752\n",
            "Epoch 44/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1092 - loss: 3.5970\n",
            "Epoch 45/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0924 - loss: 3.6174\n",
            "Epoch 46/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1338 - loss: 3.4904\n",
            "Epoch 47/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.2102 - loss: 3.4487\n",
            "Epoch 48/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1977 - loss: 3.4257\n",
            "Epoch 49/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1790 - loss: 3.4016\n",
            "Epoch 50/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2321 - loss: 3.2924\n",
            "Epoch 51/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1839 - loss: 3.3652\n",
            "Epoch 52/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2131 - loss: 3.3046\n",
            "Epoch 53/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1863 - loss: 3.2349\n",
            "Epoch 54/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1914 - loss: 3.2246\n",
            "Epoch 55/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2036 - loss: 3.1929\n",
            "Epoch 56/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2016 - loss: 3.2268\n",
            "Epoch 57/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1554 - loss: 3.0454\n",
            "Epoch 58/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1678 - loss: 3.1218\n",
            "Epoch 59/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2325 - loss: 3.0952\n",
            "Epoch 60/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2438 - loss: 2.9960\n",
            "Epoch 61/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2668 - loss: 2.9659\n",
            "Epoch 62/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2323 - loss: 2.9491\n",
            "Epoch 63/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2688 - loss: 2.8175\n",
            "Epoch 64/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2229 - loss: 2.8566\n",
            "Epoch 65/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.2580 - loss: 2.8841\n",
            "Epoch 66/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3100 - loss: 2.7443\n",
            "Epoch 67/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2725 - loss: 2.7681\n",
            "Epoch 68/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3307 - loss: 2.6070\n",
            "Epoch 69/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3308 - loss: 2.5762\n",
            "Epoch 70/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2683 - loss: 2.7333\n",
            "Epoch 71/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3212 - loss: 2.6722\n",
            "Epoch 72/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3322 - loss: 2.6447\n",
            "Epoch 73/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3580 - loss: 2.6334\n",
            "Epoch 74/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3656 - loss: 2.5237\n",
            "Epoch 75/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3491 - loss: 2.5530\n",
            "Epoch 76/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.3189 - loss: 2.6162\n",
            "Epoch 77/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.3553 - loss: 2.5029\n",
            "Epoch 78/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.3499 - loss: 2.5413\n",
            "Epoch 79/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.3374 - loss: 2.5402\n",
            "Epoch 80/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.3095 - loss: 2.4868\n",
            "Epoch 81/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.3428 - loss: 2.4101\n",
            "Epoch 82/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.3366 - loss: 2.4068\n",
            "Epoch 83/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.3457 - loss: 2.3877\n",
            "Epoch 84/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.3654 - loss: 2.3621\n",
            "Epoch 85/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.3582 - loss: 2.3428\n",
            "Epoch 86/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.3985 - loss: 2.3483\n",
            "Epoch 87/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.3622 - loss: 2.3620\n",
            "Epoch 88/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4077 - loss: 2.2945\n",
            "Epoch 89/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.3715 - loss: 2.3303\n",
            "Epoch 90/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.3784 - loss: 2.3194\n",
            "Epoch 91/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.3983 - loss: 2.2823\n",
            "Epoch 92/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.3372 - loss: 2.3023\n",
            "Epoch 93/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.3706 - loss: 2.2374\n",
            "Epoch 94/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.3486 - loss: 2.2944\n",
            "Epoch 95/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.3806 - loss: 2.2696\n",
            "Epoch 96/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4253 - loss: 2.1198\n",
            "Epoch 97/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3931 - loss: 2.1951\n",
            "Epoch 98/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3629 - loss: 2.2127\n",
            "Epoch 99/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3970 - loss: 2.2433\n",
            "Epoch 100/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4074 - loss: 2.2187\n",
            "Epoch 101/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4262 - loss: 2.1483\n",
            "Epoch 102/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4219 - loss: 2.1149\n",
            "Epoch 103/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4177 - loss: 2.1025\n",
            "Epoch 104/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4373 - loss: 2.2065\n",
            "Epoch 105/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4797 - loss: 2.0639\n",
            "Epoch 106/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4332 - loss: 2.0604\n",
            "Epoch 107/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.4602 - loss: 2.0182\n",
            "Epoch 108/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4145 - loss: 2.1054\n",
            "Epoch 109/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4361 - loss: 2.0953\n",
            "Epoch 110/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4258 - loss: 2.0870\n",
            "Epoch 111/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4020 - loss: 2.1504\n",
            "Epoch 112/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4433 - loss: 2.0562\n",
            "Epoch 113/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4734 - loss: 2.0086\n",
            "Epoch 114/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4517 - loss: 2.0482\n",
            "Epoch 115/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4569 - loss: 1.9375\n",
            "Epoch 116/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4020 - loss: 2.0426\n",
            "Epoch 117/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4207 - loss: 2.0081\n",
            "Epoch 118/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4362 - loss: 1.9847\n",
            "Epoch 119/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4569 - loss: 1.9611\n",
            "Epoch 120/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4205 - loss: 2.0139\n",
            "Epoch 121/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4446 - loss: 1.9348\n",
            "Epoch 122/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4529 - loss: 1.9872\n",
            "Epoch 123/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4402 - loss: 1.9783\n",
            "Epoch 124/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4694 - loss: 1.9046\n",
            "Epoch 125/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4183 - loss: 2.0036\n",
            "Epoch 126/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4547 - loss: 1.9648\n",
            "Epoch 127/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4795 - loss: 2.0222\n",
            "Epoch 128/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4564 - loss: 1.9583\n",
            "Epoch 129/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5196 - loss: 1.8954\n",
            "Epoch 130/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5137 - loss: 1.9028\n",
            "Epoch 131/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5019 - loss: 1.8595\n",
            "Epoch 132/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5044 - loss: 1.8468\n",
            "Epoch 133/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4753 - loss: 1.8139\n",
            "Epoch 134/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4422 - loss: 1.9036\n",
            "Epoch 135/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4368 - loss: 1.9012\n",
            "Epoch 136/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4863 - loss: 1.9102\n",
            "Epoch 137/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5085 - loss: 1.7675\n",
            "Epoch 138/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4618 - loss: 1.8773\n",
            "Epoch 139/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4211 - loss: 1.9067\n",
            "Epoch 140/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4317 - loss: 1.8526\n",
            "Epoch 141/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4764 - loss: 1.8093\n",
            "Epoch 142/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4495 - loss: 1.8298\n",
            "Epoch 143/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4517 - loss: 1.8121\n",
            "Epoch 144/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4558 - loss: 1.7940\n",
            "Epoch 145/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4514 - loss: 1.8460\n",
            "Epoch 146/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4879 - loss: 1.7410\n",
            "Epoch 147/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4959 - loss: 1.8172\n",
            "Epoch 148/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4514 - loss: 1.7875\n",
            "Epoch 149/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5093 - loss: 1.7303\n",
            "Epoch 150/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4985 - loss: 1.6723\n",
            "Epoch 151/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4770 - loss: 1.8452\n",
            "Epoch 152/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4718 - loss: 1.8328\n",
            "Epoch 153/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5186 - loss: 1.6836\n",
            "Epoch 154/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5539 - loss: 1.6365\n",
            "Epoch 155/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4884 - loss: 1.7809\n",
            "Epoch 156/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5424 - loss: 1.6557\n",
            "Epoch 157/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4893 - loss: 1.7658\n",
            "Epoch 158/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4915 - loss: 1.7030\n",
            "Epoch 159/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4979 - loss: 1.6753\n",
            "Epoch 160/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5122 - loss: 1.6716\n",
            "Epoch 161/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5049 - loss: 1.7335\n",
            "Epoch 162/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5516 - loss: 1.5935\n",
            "Epoch 163/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5432 - loss: 1.6891\n",
            "Epoch 164/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5548 - loss: 1.5769\n",
            "Epoch 165/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5183 - loss: 1.6564\n",
            "Epoch 166/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5152 - loss: 1.6808\n",
            "Epoch 167/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5141 - loss: 1.6952\n",
            "Epoch 168/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5619 - loss: 1.5681\n",
            "Epoch 169/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5608 - loss: 1.5466\n",
            "Epoch 170/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5838 - loss: 1.4606\n",
            "Epoch 171/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5359 - loss: 1.5769\n",
            "Epoch 172/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5496 - loss: 1.5738\n",
            "Epoch 173/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5192 - loss: 1.6118\n",
            "Epoch 174/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5793 - loss: 1.5523\n",
            "Epoch 175/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5420 - loss: 1.5578\n",
            "Epoch 176/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5587 - loss: 1.4966\n",
            "Epoch 177/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5536 - loss: 1.5553\n",
            "Epoch 178/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5546 - loss: 1.5435\n",
            "Epoch 179/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5846 - loss: 1.5176\n",
            "Epoch 180/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5535 - loss: 1.4821\n",
            "Epoch 181/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5358 - loss: 1.5992\n",
            "Epoch 182/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5388 - loss: 1.5654\n",
            "Epoch 183/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5846 - loss: 1.4843\n",
            "Epoch 184/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5657 - loss: 1.5458\n",
            "Epoch 185/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5700 - loss: 1.5082\n",
            "Epoch 186/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5738 - loss: 1.4912\n",
            "Epoch 187/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6138 - loss: 1.3929\n",
            "Epoch 188/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5700 - loss: 1.4438\n",
            "Epoch 189/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6049 - loss: 1.4637\n",
            "Epoch 190/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5687 - loss: 1.5135\n",
            "Epoch 191/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5854 - loss: 1.4807\n",
            "Epoch 192/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6259 - loss: 1.3298\n",
            "Epoch 193/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6340 - loss: 1.4265\n",
            "Epoch 194/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6474 - loss: 1.3972\n",
            "Epoch 195/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6318 - loss: 1.4073\n",
            "Epoch 196/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5841 - loss: 1.5071\n",
            "Epoch 197/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5853 - loss: 1.4168\n",
            "Epoch 198/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5883 - loss: 1.4858\n",
            "Epoch 199/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5756 - loss: 1.4877\n",
            "Epoch 200/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6070 - loss: 1.4409\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c8b233df610>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to predict next word(s)\n",
        "def predict_next_words(seed_text, n_words):\n",
        "    for _ in range(n_words):\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=max_seq_len-1, padding='pre')\n",
        "        predicted_probs = model.predict(token_list, verbose=0)\n",
        "        predicted = np.argmax(predicted_probs)\n",
        "        output_word = \"\"\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == predicted:\n",
        "                output_word = word\n",
        "                break\n",
        "        seed_text += \" \" + output_word\n",
        "    return seed_text\n"
      ],
      "metadata": {
        "id": "zlErj1Nk4PTB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test prediction\n",
        "seed = \"the sun\"\n",
        "next_words = 3\n",
        "print(\"Predicted:\", predict_next_words(seed, next_words))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wjzIfZ84dmp",
        "outputId": "ea7ae299-19b6-4d5b-9625-d367c9ced51c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: the sun sets in the\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test prediction\n",
        "seed = \"The children\"\n",
        "next_words = 5\n",
        "print(\"Predicted:\", predict_next_words(seed, next_words))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bg3tJcU94d8-",
        "outputId": "c6797089-0057-4230-85f4-80c5eaad82b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: The children sets in the park board\n"
          ]
        }
      ]
    }
  ]
}