{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1926230,"sourceType":"datasetVersion","datasetId":1148896}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, LSTM, Dense, Embedding\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-08T20:06:10.182049Z","iopub.execute_input":"2025-07-08T20:06:10.182317Z","iopub.status.idle":"2025-07-08T20:06:28.688691Z","shell.execute_reply.started":"2025-07-08T20:06:10.182297Z","shell.execute_reply":"2025-07-08T20:06:28.687749Z"}},"outputs":[{"name":"stderr","text":"2025-07-08 20:06:12.715053: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1752005172.985070      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1752005173.059954      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/en-fr-translation-dataset/en-fr.csv')\n\ndata = data[['en', 'fr']].iloc[:100]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T20:07:12.979299Z","iopub.execute_input":"2025-07-08T20:07:12.979906Z","iopub.status.idle":"2025-07-08T20:11:28.781481Z","shell.execute_reply.started":"2025-07-08T20:07:12.979857Z","shell.execute_reply":"2025-07-08T20:11:28.779990Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T20:12:03.759839Z","iopub.execute_input":"2025-07-08T20:12:03.760616Z","iopub.status.idle":"2025-07-08T20:12:03.787068Z","shell.execute_reply.started":"2025-07-08T20:12:03.760567Z","shell.execute_reply":"2025-07-08T20:12:03.786065Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                                  en  \\\n0  Changing Lives | Changing Society | How It Wor...   \n1                                           Site map   \n2                                           Feedback   \n3                                            Credits   \n4                                           Français   \n\n                                                  fr  \n0  Il a transformé notre vie | Il a transformé la...  \n1                                       Plan du site  \n2                                        Rétroaction  \n3                                            Crédits  \n4                                            English  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>en</th>\n      <th>fr</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Changing Lives | Changing Society | How It Wor...</td>\n      <td>Il a transformé notre vie | Il a transformé la...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Site map</td>\n      <td>Plan du site</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Feedback</td>\n      <td>Rétroaction</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Credits</td>\n      <td>Crédits</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Français</td>\n      <td>English</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"# Preprocessing\ndef preprocess_text(text):\n    text = text.lower()\n    text = text.strip()\n    return text\n\n# Correct the column names here\ndata['en'] = data['en'].apply(preprocess_text)\ndata['fr'] = data['fr'].apply(preprocess_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T20:12:13.728141Z","iopub.execute_input":"2025-07-08T20:12:13.728477Z","iopub.status.idle":"2025-07-08T20:12:13.737237Z","shell.execute_reply.started":"2025-07-08T20:12:13.728449Z","shell.execute_reply":"2025-07-08T20:12:13.736325Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Prepare inputs and outputs\neng_texts = data['en'].tolist()\nfr_texts_in = ['<start> ' + text for text in data['fr'].tolist()]   # decoder input\nfr_texts_out = [text + ' <end>' for text in data['fr'].tolist()]    # decoder output\n\n# Tokenizers\neng_tokenizer = Tokenizer()\neng_tokenizer.fit_on_texts(eng_texts)\neng_vocab_size = len(eng_tokenizer.word_index) + 1\n\nfr_tokenizer = Tokenizer()\nfr_tokenizer.fit_on_texts(fr_texts_in + fr_texts_out)\nfr_vocab_size = len(fr_tokenizer.word_index) + 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T20:33:57.411574Z","iopub.execute_input":"2025-07-08T20:33:57.411971Z","iopub.status.idle":"2025-07-08T20:33:57.427760Z","shell.execute_reply.started":"2025-07-08T20:33:57.411943Z","shell.execute_reply":"2025-07-08T20:33:57.426834Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"# Convert to sequences\nencoder_input_seq = eng_tokenizer.texts_to_sequences(eng_texts)\ndecoder_input_seq = fr_tokenizer.texts_to_sequences(fr_texts_in)\ndecoder_output_seq = fr_tokenizer.texts_to_sequences(fr_texts_out)\n\n# Padding\nmax_encoder_seq_length = max([len(seq) for seq in encoder_input_seq])\nmax_decoder_seq_length = max([len(seq) for seq in decoder_input_seq])\n\nencoder_input_seq = pad_sequences(encoder_input_seq, maxlen=max_encoder_seq_length, padding='post')\ndecoder_input_seq = pad_sequences(decoder_input_seq, maxlen=max_decoder_seq_length, padding='post')\ndecoder_output_seq = pad_sequences(decoder_output_seq, maxlen=max_decoder_seq_length, padding='post')\n\n# Decoder output needs to be one-hot encoded\ndecoder_output_data = tf.keras.utils.to_categorical(decoder_output_seq, num_classes=fr_vocab_size)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T20:31:18.948563Z","iopub.execute_input":"2025-07-08T20:31:18.948951Z","iopub.status.idle":"2025-07-08T20:31:18.987367Z","shell.execute_reply.started":"2025-07-08T20:31:18.948926Z","shell.execute_reply":"2025-07-08T20:31:18.986511Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"# Build Encoder-Decoder Model\n\nlatent_dim = 256  # Size of LSTM hidden states\n\n# Encoder\nencoder_inputs = Input(shape=(None,))\nenc_emb = Embedding(eng_vocab_size, latent_dim)(encoder_inputs)\nencoder_lstm = LSTM(latent_dim, return_state=True)\n_, state_h, state_c = encoder_lstm(enc_emb)\nencoder_states = [state_h, state_c]\n\n# Decoder\ndecoder_inputs = Input(shape=(None,))\ndec_emb_layer = Embedding(fr_vocab_size, latent_dim)\ndec_emb = dec_emb_layer(decoder_inputs)\ndecoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\ndecoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=encoder_states)\ndecoder_dense = Dense(fr_vocab_size, activation='softmax')\ndecoder_outputs = decoder_dense(decoder_outputs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T20:31:22.271785Z","iopub.execute_input":"2025-07-08T20:31:22.272988Z","iopub.status.idle":"2025-07-08T20:31:22.434608Z","shell.execute_reply.started":"2025-07-08T20:31:22.272934Z","shell.execute_reply":"2025-07-08T20:31:22.433518Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"# Final Model\nmodel = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T20:31:26.217022Z","iopub.execute_input":"2025-07-08T20:31:26.217341Z","iopub.status.idle":"2025-07-08T20:31:26.235278Z","shell.execute_reply.started":"2025-07-08T20:31:26.217316Z","shell.execute_reply":"2025-07-08T20:31:26.234201Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"# Train the Model\n\nhistory = model.fit(\n    [encoder_input_seq, decoder_input_seq],\n    decoder_output_data,\n    batch_size=64,\n    epochs=30,\n    validation_split=0.2\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T20:31:34.080046Z","iopub.execute_input":"2025-07-08T20:31:34.080817Z","iopub.status.idle":"2025-07-08T20:32:11.313123Z","shell.execute_reply.started":"2025-07-08T20:31:34.080786Z","shell.execute_reply":"2025-07-08T20:32:11.312273Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/30\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.0907 - loss: 6.4379 - val_accuracy: 0.7762 - val_loss: 5.6347\nEpoch 2/30\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 359ms/step - accuracy: 0.7199 - loss: 5.5691 - val_accuracy: 0.7762 - val_loss: 3.5131\nEpoch 3/30\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 372ms/step - accuracy: 0.7264 - loss: 3.5950 - val_accuracy: 0.7762 - val_loss: 1.9196\nEpoch 4/30\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 370ms/step - accuracy: 0.7238 - loss: 2.2252 - val_accuracy: 0.7762 - val_loss: 1.6451\nEpoch 5/30\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 401ms/step - accuracy: 0.7240 - loss: 2.0650 - val_accuracy: 0.7762 - val_loss: 1.6370\nEpoch 6/30\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 380ms/step - accuracy: 0.7261 - loss: 2.0858 - val_accuracy: 0.7762 - val_loss: 1.5562\nEpoch 7/30\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 428ms/step - accuracy: 0.7290 - loss: 1.9901 - val_accuracy: 0.7828 - val_loss: 1.4538\nEpoch 8/30\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 384ms/step - accuracy: 0.7265 - loss: 1.9032 - val_accuracy: 0.7828 - val_loss: 1.4553\nEpoch 9/30\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 381ms/step - accuracy: 0.7282 - loss: 1.8104 - val_accuracy: 0.7828 - val_loss: 1.4631\nEpoch 10/30\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 391ms/step - accuracy: 0.7266 - loss: 1.7825 - val_accuracy: 0.7828 - val_loss: 1.3998\nEpoch 11/30\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 390ms/step - accuracy: 0.7269 - loss: 1.6830 - val_accuracy: 0.7828 - val_loss: 1.3883\nEpoch 12/30\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 442ms/step - accuracy: 0.7291 - loss: 1.6356 - val_accuracy: 0.7762 - val_loss: 1.3884\nEpoch 13/30\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 426ms/step - accuracy: 0.7268 - loss: 1.6126 - val_accuracy: 0.7762 - val_loss: 1.3912\nEpoch 14/30\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 361ms/step - accuracy: 0.7286 - loss: 1.5843 - val_accuracy: 0.7762 - val_loss: 1.3930\nEpoch 15/30\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 368ms/step - accuracy: 0.7250 - loss: 1.5910 - val_accuracy: 0.7762 - val_loss: 1.3929\nEpoch 16/30\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 369ms/step - accuracy: 0.7249 - loss: 1.5790 - val_accuracy: 0.7762 - val_loss: 1.3924\nEpoch 17/30\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 364ms/step - accuracy: 0.7249 - loss: 1.5663 - val_accuracy: 0.7762 - val_loss: 1.3919\nEpoch 18/30\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 371ms/step - accuracy: 0.7249 - loss: 1.5539 - val_accuracy: 0.7762 - val_loss: 1.3917\nEpoch 19/30\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 426ms/step - accuracy: 0.7326 - loss: 1.5036 - val_accuracy: 0.7762 - val_loss: 1.3916\nEpoch 20/30\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 432ms/step - accuracy: 0.7229 - loss: 1.5560 - val_accuracy: 0.7779 - val_loss: 1.3916\nEpoch 21/30\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 370ms/step - accuracy: 0.7257 - loss: 1.5405 - val_accuracy: 0.7910 - val_loss: 1.3915\nEpoch 22/30\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 376ms/step - accuracy: 0.7335 - loss: 1.5076 - val_accuracy: 0.7852 - val_loss: 1.3919\nEpoch 23/30\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 380ms/step - accuracy: 0.7313 - loss: 1.5209 - val_accuracy: 0.7852 - val_loss: 1.3928\nEpoch 24/30\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 371ms/step - accuracy: 0.7260 - loss: 1.5485 - val_accuracy: 0.7918 - val_loss: 1.3938\nEpoch 25/30\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 368ms/step - accuracy: 0.7361 - loss: 1.5049 - val_accuracy: 0.7934 - val_loss: 1.3950\nEpoch 26/30\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 363ms/step - accuracy: 0.7362 - loss: 1.5057 - val_accuracy: 0.7959 - val_loss: 1.3967\nEpoch 27/30\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 367ms/step - accuracy: 0.7354 - loss: 1.5069 - val_accuracy: 0.7959 - val_loss: 1.3990\nEpoch 28/30\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 365ms/step - accuracy: 0.7351 - loss: 1.5146 - val_accuracy: 0.7951 - val_loss: 1.4016\nEpoch 29/30\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 372ms/step - accuracy: 0.7423 - loss: 1.4742 - val_accuracy: 0.7959 - val_loss: 1.4048\nEpoch 30/30\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 357ms/step - accuracy: 0.7373 - loss: 1.5123 - val_accuracy: 0.7959 - val_loss: 1.4083\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"# Build Inference Models\n\n# Encoder model for inference\nencoder_model = Model(encoder_inputs, encoder_states)\n\n# Decoder model for inference\ndecoder_state_input_h = Input(shape=(latent_dim,))\ndecoder_state_input_c = Input(shape=(latent_dim,))\ndecoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n\n# Reuse decoder embedding layer\ndec_emb2 = dec_emb_layer(decoder_inputs)\ndecoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\ndecoder_states2 = [state_h2, state_c2]\ndecoder_outputs2 = decoder_dense(decoder_outputs2)\n\ndecoder_model = Model(\n    [decoder_inputs] + decoder_states_inputs,\n    [decoder_outputs2] + decoder_states2\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T20:32:15.717557Z","iopub.execute_input":"2025-07-08T20:32:15.717912Z","iopub.status.idle":"2025-07-08T20:32:15.731816Z","shell.execute_reply.started":"2025-07-08T20:32:15.717867Z","shell.execute_reply":"2025-07-08T20:32:15.730966Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"# Function for Translation\n\nreverse_eng_word_index = {idx: word for word, idx in eng_tokenizer.word_index.items()}\nreverse_fr_word_index = {idx: word for word, idx in fr_tokenizer.word_index.items()}\n\ndef decode_sequence(input_seq):\n    # Encode input and get initial decoder states\n    states_value = encoder_model.predict(input_seq)\n\n    # Initialize target sequence with <start> token\n    target_seq = np.zeros((1, 1))\n    target_seq[0, 0] = fr_tokenizer.word_index['<start>']\n\n    decoded_sentence = ''\n    stop_condition = False\n\n    while not stop_condition:\n        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n\n        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n        sampled_word = reverse_fr_word_index.get(sampled_token_index, '')\n\n        if sampled_word == '<end>' or len(decoded_sentence.split()) > max_decoder_seq_length:\n            stop_condition = True\n        else:\n            decoded_sentence += ' ' + sampled_word\n\n        # Update target sequence and states\n        target_seq = np.zeros((1, 1))\n        target_seq[0, 0] = sampled_token_index\n        states_value = [h, c]\n\n    return decoded_sentence.strip()\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T20:32:20.196447Z","iopub.execute_input":"2025-07-08T20:32:20.196746Z","iopub.status.idle":"2025-07-08T20:32:20.205213Z","shell.execute_reply.started":"2025-07-08T20:32:20.196723Z","shell.execute_reply":"2025-07-08T20:32:20.204233Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"# Test Translation\n\ndef translate_sentence(sentence):\n    sentence = preprocess_text(sentence)\n    seq = eng_tokenizer.texts_to_sequences([sentence])\n    seq = pad_sequences(seq, maxlen=max_encoder_seq_length, padding='post')\n    translation = decode_sequence(seq)\n    print(f\"Input sentence: {sentence}\")\n    print(f\"Translated sentence: {translation}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T20:34:15.830308Z","iopub.execute_input":"2025-07-08T20:34:15.830614Z","iopub.status.idle":"2025-07-08T20:34:15.836203Z","shell.execute_reply.started":"2025-07-08T20:34:15.830581Z","shell.execute_reply":"2025-07-08T20:34:15.835285Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"# Example\ntranslate_sentence(\"i am very happy today\")\ntranslate_sentence(\"where are you going\")\ntranslate_sentence(\"this is a beautiful city\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T20:34:06.175578Z","iopub.execute_input":"2025-07-08T20:34:06.175929Z","iopub.status.idle":"2025-07-08T20:34:06.347008Z","shell.execute_reply.started":"2025-07-08T20:34:06.175877Z","shell.execute_reply":"2025-07-08T20:34:06.345948Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/1590764590.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Example\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtranslate_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"i am very happy today\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtranslate_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"where are you going\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtranslate_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"this is a beautiful city\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/1000387074.py\u001b[0m in \u001b[0;36mtranslate_sentence\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mseq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meng_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mseq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_encoder_seq_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'post'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtranslation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Input sentence: {sentence}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Translated sentence: {translation}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/3547209078.py\u001b[0m in \u001b[0;36mdecode_sequence\u001b[0;34m(input_seq)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Initialize target sequence with <start> token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mtarget_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtarget_seq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfr_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'<start>'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mdecoded_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: '<start>'"],"ename":"KeyError","evalue":"'<start>'","output_type":"error"}],"execution_count":43}]}